%YAML 1.2
---
public_folder: public
services:
  upload_files:
    evaluator: [python,services/upload_files_server.py]
    files:
      - instance
      - model
      - datafile
    args:
      flag_instance:
        regex: ^(0|1)$
        default: 0
    lang:
      regex: ^(hardcoded|hardcoded_ext|en|it)$
      default: it
  gimme_guide_files:
    description: 'Call this service to get didactic material that can guide you in getting the most out of this exercise. For example, the files statement.* offer a statement of the main problem this exercise is about.'
    evaluator: [python,services/gimme_guide_files_server.py]
    args:
      statement.txt:
        regex: ^(0|1)$
        default: 0
        explain: If this flag is set to 1 then the service downloads the file statement.txt      
      statement.md:
        regex: ^(0|1)$
        default: 0
        explain: If this flag is set to 1 then the service downloads the file statement.md      
      lang:
        regex: ^(hardcoded|hardcoded_ext|en|it)$
        default: it
  gimme_instance:
    description: 'Call this service to get an instance for the Longest Subsequence Problem (LCS), i.e., a pair of strings s and t over a same alphabet, and of length m and n, respectively. You have two main options when calling this service:\n    [instance_spec=catalogue_name] to get the instance with a specific id out from the named catalogue of hardcoded instances.\n    [instance_spec=random] to get the pseudo-random instance for a given seed. As seed, you can use any integer from 100000 to 999999 or let the service choose the seed at random (seed=random_seed). When you want to recall an LCS instance you have already met with this or other services, you only need to recall its seed and the other details in its instance descriptor. By the \''instance descriptor\'' of a pseudo-random LCS instance we mean the triple <m,n,alphabet,seed>.\n   The two strings s and t comprising the instance are returned by the service in the form of a stream. You may ask for this stream to get downloaded in a file on your local machine and/or displayed on the screen. Our format for streams storing LCS instances is the following: the first line contains the two integers m and n; then follow 2 lines, the first contains the string s and the second contains the string t.'
    evaluator: [python,services/gimme_instance_server.py]
    args:
      instance_spec:
        regex: ^(random|catalogue1)$
        default: random
        explain: 'choose an option among:' 
        explain1: '[random] the service uses the seed specificated to generate and return the pseudo-random instance <m,n,alphabet,seed>.'
        explain2: '[catalogue1] the service will return an instance taken from a catalogue of hardcoded instances (the catalogue named \''catalogue1\''). More precisely, the instance returned is the one with the given instance_id.'
      m:
        regex: ^([1-9][0-9]{0,1})$
        default: 4
        explain: Length of the string s.
      n:
        regex: ^([1-9][0-9]{0,1})$
        default: 4
        explain: Length of the string t.
      alphabet:
        regex: ^(dna|lowercase|lowercase_uppercase)$
        default: dna
        explain: The alphabet over which the two strings will be created.
      seed:
        explain: 'Set up this argument when you hold the seed and the instance descriptor of the specific instance that you want to be produced by the service (whether downloaded in local as a file or displayed on your terminal screen). By an \''instance descriptor\'' we mean a triple <m,n,alphabet,seed> that you may have got from previous calls to this or other services for this problem. When this argument is left to its default value (random_seed) then the service first chooses a seed at random (and communicates it to the user) and then produces the pseudo-random instance <m,n,seed>.'
        regex: ^(random_seed|[1-9][0-9]{5,5})$
        default: random_seed
      instance_id:
        regex: ^([1-9][0-9]*)$
        default: 1
        explain: 'This argument is taken into account when instance_spec=instance_id. It is used to identify a particular instance within the catalogue of hardcoded instances. If you hold the whole problem in local (all sources) then this catalogue of hardcoded instances is automatically set up with make when setting up the server.'
      instance_format:
        regex: ^(only_strings.txt|with_m_and_n.txt|dat)$
        default: only_strings.txt
        explain: choose the encoding for the txt input file.
      silent:
        regex: ^(0|1)$
        default: 0
        explain: If this flag is set to 1 then only the bare instance will be printed. In this way, if you redirect the output to file ('>') you will get a valid instance file for the other services.
      display:
        regex: ^(0|1)$
        default: 1
        explain: If this flag is set to 1 then the instance file is listed by the service.
      download:
        regex: ^(0|1)$
        default: 0
        explain: 'If this flag is set to 1 then the instance file is downloaded in the folder whose path is specified by means of the -o flagof the folder from which this TALight service call has been issued.'
      lang:
        regex: ^(hardcoded|hardcoded_ext|en|it)$
        default: it
  
  gimme_sol:
    description: 'This service provides you with a solution for an instance (either provided by you or generated at random) of the LCS problem. You can even call this service on an already encountered instance (also met with other services): a random instance can be reconstructed from m, n, alphabet, and its random seed.'
    evaluator: [python, services/gimme_sol_server.py]
    args:
      instance_spec:
        regex: ^(random|terminal|TA_send_files_bot)$
        default: random
        explain: 'choose the way to input your two strings among:' 
        explain1: '[random] the service generate a seed at random and then returns it as well as the pseudo-random instance <m,n,alphabet,seed>.'
        explain2: '[terminal] you enter your instance (two strings) directly by either typing it string by string or through cut and paste operations.'
        explain3: '[TA_send_files_bot] with this, you can send to the service an instance (two strings) encoded in a file sitting in your machine. To send the file you must use the TA_send_files_bot.py bot placed in the model_lcs/bots/ directory. Call the service with: rtal connect model_lcs gimme_sol -ainstance_spec=TA_send_files_bot -- path_to_bot_dir/TA_send_files_bot.py path_to_instance_file_dir/your_instance.txt.'
      m:
        regex: ^([1-9][0-9]{0,1})$
        default: 4
        explain: Length of the string s.
      n:
        regex: ^([1-9][0-9]{0,1})$
        default: 4
        explain: Length of the string t.
      alphabet:
        regex: ^(dna|lowercase|lowercase_uppercase)$
        default: dna
        explain: The alphabet over which the two strings will be created.
      seed:
        explain: specify the numeric code (any integer in the interval [100000,999999]) to work with an already met pseudo-random instance. When this argument is left to its default value (random_seed) then the service chooses a seed at random, communicates it to the user, and works on the unique pseudo-random instance <m,n,seed>.
        regex: ^(random_seed|[1-9][0-9]{5,5})$
        default: random_seed
      sol_format:
        regex: ^(subsequence|annotated_subseq)$
        default: subsequence
        explain: 'choose how to encode the solution. Either just as a string which is a subsequence of both s and t, or also annotating each of its characters (each disposed on a different line) with its position in s and its position in t, separated by spaces.'
      lang:
        regex: ^(hardcoded|hardcoded_ext|en|it)$
        default: it
  
  check_sol:
    description: 'This service checks your solution for an instance (either provided by you or generated at random) of the LCS problem. You can even call this service on an already encountered random instance (also met with other services): a random instance can be reconstructed from m, n, alphabet and its random seed.'
    evaluator: [python, services/check_sol_server.py]
    args:
      instance_spec:
        regex: ^(random|terminal|TA_send_files_bot)$
        default: random
        explain: 'choose the way to input your two strings among:' 
        explain1: '[random] the service generate a seed at random and then returns it as well as the pseudo-random instance <m,n,alphabet,seed>.'
        explain3: '[terminal] you enter your instance (two strings) directly by either typing it string by string or through cut and paste operations.'
        explain4: '[TA_send_files_bot] with this, you can send to the service an instance (two strings) encoded in a file sitting in your machine. To send the file you must use the TA_send_files_bot.py bot placed in the model_lcs/bots/ directory. Call the service with: rtal connect model_lcs gimme_sol -ainstance_spec=TA_send_files_bot -- path_to_bot_dir/TA_send_files_bot.py path_to_instance_file_dir/your_instance_with_solution.txt.'
      m:
        regex: ^([1-9][0-9]{0,1})$
        default: 4
        explain: Length of the string s.
      n:
        regex: ^([1-9][0-9]{0,1})$
        default: 4
        explain: Length of the string t.
      alphabet:
        regex: ^(dna|lowercase|lowercase_uppercase)$
        default: dna
        explain: The alphabet over which the two strings will be created.
      seed:
        explain: specify the numeric code (any integer in the interval [100000,999999]) to work with an already met pseudo-random instance. When this argument is left to its default value (random_seed) then the service chooses a seed at random, communicates it to the user, and works on the unique pseudo-random instance <m,n,alphabet,seed>.
        regex: ^(random_seed|[1-9][0-9]{5,5})$
        default: random_seed
      sol_format:
        regex: ^(subsequence|annotated_subseq)$
        default: subsequence
        explain: 'choose how to encode the solution. Either just as a string which is a subsequence of both s and t, or also annotating each of its characters (each disposed on a different line) with its position in s and its position in t, separated by spaces.'
      lang:
        regex: ^(hardcoded|hardcoded_ext|en|it)$
        default: it
  
  try_GMPL_model:
    description: 'This service allows you to validate (or also submit) your GMPL models for single instances of the LCS problem (input: two strings; output: a longest common subsequence). Even if you do not have `glpsol` installed on your machine, still with this service you can send to our server the .mod file containing your GMPL model and a .dat file containing an instance of the problem. The service runs a `glpsol` engine on your .mod and .dat files to build an explicit LP or ILP formulation of the instance and possibly solve it. If the flag `display_output` is set to 1, the output of `glpsol` will be echoed on your screen (on your local machine). We advocate that your model writes down on a file `solution.txt` the solution it finds. If the flag `display_solution` is set to 1, this file will be listed on your screen. If the flag `check_solution` is set to 1 then the service also checks the feasibility and optimality of the solution produced by your model for that instance. However, for these checks to take place two conditions must be met. First, the file `solution.txt` should strictly adhere to one of our supported formats (you can find examples in the `examples` folder in the archive downloaded with `rtal get model_lcs`, and you can get further examples through the service `gimme_sol`). Second, you must submit also the .instance file besides the .dat file and .mod file. Examples for the supported formats of the .instance file can be found in the `examples` directory or obtained from the service `gimme_sol`. When you have a personal TALight token (assigned to you for an exam or with the enrollment to a course), and you want that a positive evaluation gets accounted to you, then just supply your token to the service. Only the positive submissions are taken in considerations and are never overwritten by the bad ones.' 
    example1: [when the model does not write on a file `solution.txt`, '\n     rtal connect model_lcs try_GMPL_model -fmod=path_to_your_model_file_dir/your_lcs.mod -fdat=path_to_instance_file_dir/your_lcs.dat']
    example2: [to visualize the solution written in the file `solution.txt`, '\n     rtal connect model_lcs try_GMPL_model -adisplay_solution=1 -fmod=path_to_your_model_file_dir/your_lcs.mod -fdat=path_to_instance_file_dir/your_lcs.dat']
    example3: [to ask validation of the solution written in the file `solution.txt`, '\n     rtal connect model_lcs try_GMPL_model -adisplay_solution=1 -acheck_solution=1 -fmod=path_to_your_model_file_dir/your_lcs.mod -fdat=path_to_instance_file_dir/your_lcs.dat -finstance=path_to_input_file/input.txt']
    example4: [to get credits for this instance in case of feasibility/optimality of the solution written in the file `solution.txt` by your model, '\n     rtal connect model_lcs try_GMPL_model -atoken=123456 -adisplay_solution=1 -acheck_solution=1 -fmod=path_to_your_model_file_dir/your_lcs.mod -fdat=path_to_instance_file_dir/your_lcs.dat -finstance=path_to_input_file/input.txt']
    evaluator: [python, services/try_GMPL_model_server.py]
    files:
      - instance
      - mod
      - dat
    args:
      display_output:
        regex: ^(0|1)$
        default: 1
        explain: If this flag is set to 1 then the service displays the output of the `glpsol` engine when running your model and instance.
      display_error:
        regex: ^(0|1)$
        default: 0
        explain: If this flag is set to 1 then the service displays the log of the `glpsol` engine when running your model and instance.
      display_solution:
        regex: ^(0|1)$
        default: 0
        explain: If this flag is set to 1 then the service displays the content of the solution.txt file created by your model. This display is a raw listing of the file as it is (might help your debugging from remote).
      display_explicit_formulation:
        regex: ^(0|1)$
        default: 0
        explain: If this flag is set to 1 then the service displays the explicit formulation obtained from your abstract model applied to the specific instance.
      explicit_formulation_format:
        regex: ^(mps|freemps|lp|glp)$
        default: glp
      check_solution:
        regex: ^(0|1)$
        default: 0
        explain: If this flag is set to 1 then, the solution obtained from GLPSOL will be checked. In order to perform this check, it is mandatory that also the input.txt file is sent to the sever via the TA_send_files_bot.py
      instance_format:
        regex: ^(only_strings|with_m_and_n)$
        default: only_strings
        explain: 'choose the format of the instance file.'
      sol_format:
        regex: ^(subsequence|annotated_subseq)$
        default: subsequence
        explain: 'choose how to encode the solution. Either just as a string which is a subsequence of both s and t, or also annotating each of its characters (each disposed on a different line) with its position in s and its position in t, separated by spaces.'
      token:
        regex: ^(anonymous|[1-9][0-9]{5,5})$
        default: anonymous
      lang: 
        regex: ^(hardcoded|hardcoded_ext|en|it)$
        default: it
  
  get_my_instances:
    description: 'If you hold a personal token to a course or exam, and intend to score points on this problem, you should first use this service in order to get the instances of your personal assignement, and next use the service `try_GMPL_model` or `try_solution` to check and/or submit your model or solution on each particular instance you can manage. After calling the service `get_my_instances` you will find the instances within the subfolder `output` of your current directory. Use the rtal -o argument if you prefer a different path or folder name.' 
    evaluator: [python, services/get_my_instances_server.py]
    args:
      group:
        regex: ^(catalogue1|random)$
        default: random
      instance_format:
        regex: ^(only_strings.txt|with_m_and_n.txt)$
        default: only_strings.txt
        explain: 'choose the format of the instance file.'
      token:
        regex: ^(anonymous|[1-9][0-9]{5,5})$
        default: anonymous
      lang: 
        regex: ^(hardcoded|hardcoded_ext|en|it)$
        default: it
  
  try_explicit_formulation:
    description: 'This service takes in input an explicit LP or ILP instance (i.e., a system of linear constraints on a set of real or possibly integer variables (plus, possibly, an objective function) and applies a solver to it in order to obtain a solution. The service returns the outcome of the computation performed by the solver. Call the service with:\n    rtal connect model_lcs try_explicit_formulation -- path_to_bot_dir/TA_send_files_bot.py ef=path_to_your_formulation_file_dir/your_formulation_file\nHere, your formulation file should be valid for the choosen format. See the argument `format` for the currently supported formats.'
    evaluator: [python, services/try_explicit_formulation_server.py]
    args:
      display_output:
        regex: ^(0|1)$
        default: 0
        explain: If this flag is set to 1 then the service displays the output of the `glpsol` engine when running your model and instance.
      display_error:
        regex: ^(0|1)$
        default: 0
        explain: If this flag is set to 1 then the service displays the log of the `glpsol` engine when running your model and instance.
      format:
        regex: ^(mps|freemps|lp|glp|math)$
        default: glp
      lang: 
        regex: ^(hardcoded|hardcoded_ext|en|it)$
        default: it

  eval_GMPL_model:
    description: 'use this service to evaluate a GMPL model of yours. It is assumed that this model is compliant with the .dat file format specifyied by the parameter `dat_style`. Examples of the supported dat styles are given in the folder `examples` where each example instance is encoded in every supported dat style (filename and extensions in the form `instance_name`.`dat_style`.dat) as well as in other formats. These instances comprise the set of public examples. For each tested instance, the service displays its instance_id so that if your model fails you have this handle on an invalidating instance. You can then use the service `gimme_instance` to download this instance in local and/or the service `try_GMPL_model` (even directly) to get more detailed feedback. Call the service with:\n    rtal connect model_lcs eval_GMPL_model -- path_to_bot_dir/TA_send_files_bot.py path_to_model_file_dir/your_lcs.mod'
    evaluator: [python, services/eval_GMPL_model_server.py]
    args:
      goal:
        regex: ^(public_examples|at_most_20_dna|at_most_50_lowercase|at_most_80_lowercase_uppercase)$
        default: at_most_20_dna
        explain: To solve bigger instances you might need smarter models, either using some tricks or, even more powerful, a better understanding of the structural properties of the problem.
      dat_style:
        regex: ^(default)$
        default: default
        explain: 'choose how to encode the dat file. For now there is only one format'
      sol_format:
        regex: ^(subsequence|annotated_subseq)$
        default: subsequence
        explain: 'choose how to encode the solution. Either just as a string which is a subsequence of both s and t, or also annotating each of its characters (each disposed on a different line) with its position in s and its position in t, separated by spaces.'
      lang:
        regex: ^(hardcoded|hardcoded_ext|en|it)$
        default: it

  synopsis:
    evaluator: [python, services/synopsis/synopsis_server.py]
    args:
      service:
        regex: ^((\S)+)$
        default: synopsis
        explain: any string without space characters but meant to specify one of the services of the problem {problem}
      lang:
        regex: ^(hardcoded|hardcoded_ext|en|it)$
        default: it
      metafile:
        regex: ^(main|en|it)$
        default: main
...
